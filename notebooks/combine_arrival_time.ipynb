{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1358cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18df61af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/spark-3.1.2-bin-hadoop3.2/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "22/11/03 08:38:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Spark session & context\n",
    "spark = (SparkSession\n",
    "         .builder\n",
    "         .master(\"spark://spark:7077\")\n",
    "         .appName(\"fix_data\")\n",
    "         # Add postgres jar\n",
    "         .config(\"spark.driver.extraClassPath\", \"/home/jovyan/work/jars/postgresql-9.4.1207.jar\")\n",
    "         .getOrCreate())\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a54957",
   "metadata": {},
   "source": [
    "# Arrival Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1050283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/notebooks\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7219f1d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/11/03 08:41:01 WARN TaskSetManager: Lost task 0.0 in stage 1.0 (TID 4) (172.18.0.4 executor 1): java.io.FileNotFoundException: File file:/home/jovyan/work/notebooks/movies.csv does not exist\n",
      "It is possible the underlying files have been updated. You can explicitly invalidate the cache in Spark by running 'REFRESH TABLE tableName' command in SQL or by recreating the Dataset/DataFrame involved.\n",
      "\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:124)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:169)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:93)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:345)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/11/03 08:41:01 ERROR TaskSetManager: Task 0 in stage 1.0 failed 4 times; aborting job\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o56.load.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 4 times, most recent failure: Lost task 0.3 in stage 1.0 (TID 7) (172.18.0.4 executor 1): java.io.FileNotFoundException: File file:/home/jovyan/work/notebooks/movies.csv does not exist\nIt is possible the underlying files have been updated. You can explicitly invalidate the cache in Spark by running 'REFRESH TABLE tableName' command in SQL or by recreating the Dataset/DataFrame involved.\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:124)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:169)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:93)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:345)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2258)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2207)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2206)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2206)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1079)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1079)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1079)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2445)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2387)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2376)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2196)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2217)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2236)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:472)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:425)\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:47)\n\tat org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:3696)\n\tat org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:2722)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2722)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2929)\n\tat org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$.infer(CSVDataSource.scala:112)\n\tat org.apache.spark.sql.execution.datasources.csv.CSVDataSource.inferSchema(CSVDataSource.scala:65)\n\tat org.apache.spark.sql.execution.datasources.csv.CSVFileFormat.inferSchema(CSVFileFormat.scala:62)\n\tat org.apache.spark.sql.execution.datasources.DataSource.$anonfun$getOrInferFileFormatSchema$11(DataSource.scala:209)\n\tat scala.Option.orElse(Option.scala:447)\n\tat org.apache.spark.sql.execution.datasources.DataSource.getOrInferFileFormatSchema(DataSource.scala:206)\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:419)\n\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:325)\n\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$3(DataFrameReader.scala:307)\n\tat scala.Option.getOrElse(Option.scala:189)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:307)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:239)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\nCaused by: java.io.FileNotFoundException: File file:/home/jovyan/work/notebooks/movies.csv does not exist\nIt is possible the underlying files have been updated. You can explicitly invalidate the cache in Spark by running 'REFRESH TABLE tableName' command in SQL or by recreating the Dataset/DataFrame involved.\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:124)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:169)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:93)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:345)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2146/162401724.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m df = (spark.read.format('csv')\n\u001b[0m\u001b[1;32m      2\u001b[0m               \u001b[0;34m.\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"header\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m              .load(\"movies.csv\"))\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morderBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprintSchema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, path, format, schema, **options)\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOUTPUT_CONVERTER\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mREFERENCE_TYPE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                 raise Py4JJavaError(\n\u001b[0m\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m                     format(target_id, \".\", name), value)\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o56.load.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 4 times, most recent failure: Lost task 0.3 in stage 1.0 (TID 7) (172.18.0.4 executor 1): java.io.FileNotFoundException: File file:/home/jovyan/work/notebooks/movies.csv does not exist\nIt is possible the underlying files have been updated. You can explicitly invalidate the cache in Spark by running 'REFRESH TABLE tableName' command in SQL or by recreating the Dataset/DataFrame involved.\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:124)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:169)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:93)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:345)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2258)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2207)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2206)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2206)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1079)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1079)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1079)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2445)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2387)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2376)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2196)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2217)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2236)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:472)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:425)\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:47)\n\tat org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:3696)\n\tat org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:2722)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2722)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2929)\n\tat org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$.infer(CSVDataSource.scala:112)\n\tat org.apache.spark.sql.execution.datasources.csv.CSVDataSource.inferSchema(CSVDataSource.scala:65)\n\tat org.apache.spark.sql.execution.datasources.csv.CSVFileFormat.inferSchema(CSVFileFormat.scala:62)\n\tat org.apache.spark.sql.execution.datasources.DataSource.$anonfun$getOrInferFileFormatSchema$11(DataSource.scala:209)\n\tat scala.Option.orElse(Option.scala:447)\n\tat org.apache.spark.sql.execution.datasources.DataSource.getOrInferFileFormatSchema(DataSource.scala:206)\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:419)\n\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:325)\n\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$3(DataFrameReader.scala:307)\n\tat scala.Option.getOrElse(Option.scala:189)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:307)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:239)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\nCaused by: java.io.FileNotFoundException: File file:/home/jovyan/work/notebooks/movies.csv does not exist\nIt is possible the underlying files have been updated. You can explicitly invalidate the cache in Spark by running 'REFRESH TABLE tableName' command in SQL or by recreating the Dataset/DataFrame involved.\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:124)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:169)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:93)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:345)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n"
     ]
    }
   ],
   "source": [
    "df = (spark.read.format('csv')\n",
    "              .option(\"header\", True)\n",
    "             .load(\"movies.csv\"))\n",
    "df = df.orderBy(df.time.asc())\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eb5c7ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- station_lat: double (nullable = true)\n",
      " |-- station_long: double (nullable = true)\n",
      " |-- distance: double (nullable = true)\n",
      " |-- time: string (nullable = true)\n",
      " |-- station_num: integer (nullable = true)\n",
      " |-- loop_num: integer (nullable = true)\n",
      " |-- path: string (nullable = true)\n",
      " |-- route_num: integer (nullable = true)\n",
      " |-- gps_imei: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = (df.withColumn(\"station_lat\",col(\"station_lat\").cast('double'))\n",
    "              .withColumn(\"station_long\", col(\"station_long\").cast(\"double\"))\n",
    "              .withColumn(\"distance\", col(\"distance\").cast(\"double\"))\n",
    "              .withColumn(\"time\", col(\"time\").cast(StringType()))\n",
    "              .withColumn(\"station_num\", col(\"station_num\").cast(IntegerType()))\n",
    "              .withColumn(\"loop_num\", col(\"loop_num\").cast(IntegerType()))\n",
    "              .withColumn(\"route_num\", col(\"route_num\").cast(IntegerType()))\n",
    "              .withColumn(\"gps_imei\", col(\"gps_imei\").cast(LongType()))\n",
    "             )\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "98ff39da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class pythonFunctions:\n",
    "    @udf\n",
    "    def generate_uuid():\n",
    "        return str(uuid.uuid4().hex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c6aade5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"uuid\", pythonFunctions.generate_uuid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c7fdc2c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_lat</th>\n",
       "      <th>station_long</th>\n",
       "      <th>distance</th>\n",
       "      <th>time</th>\n",
       "      <th>station_num</th>\n",
       "      <th>loop_num</th>\n",
       "      <th>path</th>\n",
       "      <th>route_num</th>\n",
       "      <th>gps_imei</th>\n",
       "      <th>uuid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.659400</td>\n",
       "      <td>100.535141</td>\n",
       "      <td>3.399549</td>\n",
       "      <td>2022-03-22 08:03:15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>go</td>\n",
       "      <td>6</td>\n",
       "      <td>864507039672166</td>\n",
       "      <td>10a3f1da7c1849f087b59350fa6147a0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.659541</td>\n",
       "      <td>100.533023</td>\n",
       "      <td>7.568617</td>\n",
       "      <td>2022-03-22 08:04:45</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>go</td>\n",
       "      <td>6</td>\n",
       "      <td>864507039672166</td>\n",
       "      <td>70595d1bb73247248410552d2ea7134a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.660282</td>\n",
       "      <td>100.531442</td>\n",
       "      <td>2.932296</td>\n",
       "      <td>2022-03-22 08:05:45</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>go</td>\n",
       "      <td>6</td>\n",
       "      <td>864507039672166</td>\n",
       "      <td>6141bf71ebd84dd78c7542c99d386322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.660546</td>\n",
       "      <td>100.529004</td>\n",
       "      <td>86.640243</td>\n",
       "      <td>2022-03-22 08:07:15</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>go</td>\n",
       "      <td>6</td>\n",
       "      <td>864507039672166</td>\n",
       "      <td>6c4d2b79c69445e5a8d2e51527d11368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.661442</td>\n",
       "      <td>100.526945</td>\n",
       "      <td>62.207002</td>\n",
       "      <td>2022-03-22 08:08:30</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>go</td>\n",
       "      <td>6</td>\n",
       "      <td>864507039672166</td>\n",
       "      <td>e8dcac4e47744940b1c079274e3c7f85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   station_lat  station_long   distance                 time  station_num  \\\n",
       "0    13.659400    100.535141   3.399549  2022-03-22 08:03:15            0   \n",
       "1    13.659541    100.533023   7.568617  2022-03-22 08:04:45            1   \n",
       "2    13.660282    100.531442   2.932296  2022-03-22 08:05:45            2   \n",
       "3    13.660546    100.529004  86.640243  2022-03-22 08:07:15            3   \n",
       "4    13.661442    100.526945  62.207002  2022-03-22 08:08:30            4   \n",
       "\n",
       "   loop_num path  route_num         gps_imei                              uuid  \n",
       "0         0   go          6  864507039672166  10a3f1da7c1849f087b59350fa6147a0  \n",
       "1         0   go          6  864507039672166  70595d1bb73247248410552d2ea7134a  \n",
       "2         0   go          6  864507039672166  6141bf71ebd84dd78c7542c99d386322  \n",
       "3         0   go          6  864507039672166  6c4d2b79c69445e5a8d2e51527d11368  \n",
       "4         0   go          6  864507039672166  e8dcac4e47744940b1c079274e3c7f85  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe6c15d",
   "metadata": {},
   "source": [
    "# Link Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "677fd17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "#establishing the connection\n",
    "conn = psycopg2.connect(\n",
    "   database=\"test\", user='test', password='postgres', host='ea_pgdb', port= '5432'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14712702",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting auto commit false\n",
    "conn.autocommit = True\n",
    "\n",
    "#Creating a cursor object using the cursor() method\n",
    "cursor = conn.cursor()\n",
    "\n",
    "#Retrieving data\n",
    "cursor.execute('''SELECT * from arrival_time where route_num='6' and path='go';\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50687524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "#Fetching 1st row from the table\n",
    "result = cursor.fetchall();\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "081e103e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "24e7a142",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current gps imei: 866381052370019, Current path: go\n",
      "Current gps imei: 866381052370324, Current path: go\n",
      "Current gps imei: 868998030645952, Current path: go\n",
      "Current gps imei: 866381052370274, Current path: go\n",
      "Current gps imei: 866381052397160, Current path: go\n",
      "Current gps imei: 864507039641906, Current path: go\n",
      "Current gps imei: 866381052397095, Current path: go\n",
      "Current gps imei: 869530043171145, Current path: go\n",
      "Current gps imei: 866381052399695, Current path: go\n",
      "Current gps imei: 866381052396907, Current path: go\n",
      "Current gps imei: 868998030588186, Current path: go\n",
      "Current gps imei: 866381052396683, Current path: go\n",
      "Current gps imei: 866381052394621, Current path: go\n",
      "Current gps imei: 868998030595546, Current path: go\n",
      "Current gps imei: 868998030635219, Current path: go\n",
      "Current gps imei: 866381052370019, Current path: back\n",
      "Current gps imei: 866381052370324, Current path: back\n",
      "Current gps imei: 868998030645952, Current path: back\n",
      "Current gps imei: 866381052370274, Current path: back\n",
      "Current gps imei: 866381052397160, Current path: back\n",
      "Current gps imei: 864507039641906, Current path: back\n",
      "Current gps imei: 866381052397095, Current path: back\n",
      "Current gps imei: 869530043171145, Current path: back\n",
      "Current gps imei: 866381052399695, Current path: back\n",
      "Current gps imei: 866381052396907, Current path: back\n",
      "Current gps imei: 868998030588186, Current path: back\n",
      "Current gps imei: 866381052396683, Current path: back\n",
      "Current gps imei: 866381052394621, Current path: back\n",
      "Current gps imei: 868998030595546, Current path: back\n",
      "Current gps imei: 868998030635219, Current path: back\n",
      "Current gps imei: 866381052370019, Current path: go\n",
      "Current gps imei: 868998030587691, Current path: go\n",
      "Current gps imei: 866381052370324, Current path: go\n",
      "Current gps imei: 867553050796408, Current path: go\n",
      "Current gps imei: 867553050806694, Current path: go\n",
      "Current gps imei: 868998030645952, Current path: go\n",
      "Current gps imei: 866381052370274, Current path: go\n",
      "Current gps imei: 868998030639021, Current path: go\n",
      "Current gps imei: 868998030633206, Current path: go\n",
      "Current gps imei: 864507039711451, Current path: go\n",
      "Current gps imei: 866381052397160, Current path: go\n",
      "Current gps imei: 864507039641906, Current path: go\n",
      "Current gps imei: 868998030618942, Current path: go\n",
      "Current gps imei: 864507039711535, Current path: go\n",
      "Current gps imei: 869530043171988, Current path: go\n",
      "Current gps imei: 866381052390660, Current path: go\n",
      "Current gps imei: 866381052394969, Current path: go\n",
      "Current gps imei: 866381052393128, Current path: go\n",
      "Current gps imei: 866381052397095, Current path: go\n",
      "Current gps imei: 869530043171145, Current path: go\n",
      "Current gps imei: 864507039674154, Current path: go\n",
      "Current gps imei: 868998030627521, Current path: go\n",
      "Current gps imei: 868998030635771, Current path: go\n",
      "Current gps imei: 866381052399695, Current path: go\n",
      "Current gps imei: 866381052396907, Current path: go\n",
      "Current gps imei: 868998030587931, Current path: go\n",
      "Current gps imei: 866381052399125, Current path: go\n",
      "Current gps imei: 868998030588186, Current path: go\n",
      "Current gps imei: 863835027811913, Current path: go\n",
      "Current gps imei: 864507039665376, Current path: go\n",
      "Current gps imei: 866381052396683, Current path: go\n",
      "Current gps imei: 868998030634774, Current path: go\n",
      "Current gps imei: 864507039672166, Current path: go\n",
      "Current gps imei: 864507039673982, Current path: go\n",
      "Current gps imei: 868998030634154, Current path: go\n",
      "Current gps imei: 869530043171822, Current path: go\n",
      "Current gps imei: 863835026096490, Current path: go\n",
      "Current gps imei: 868998030615351, Current path: go\n",
      "Current gps imei: 869530043173083, Current path: go\n",
      "Current gps imei: 864507039720817, Current path: go\n",
      "Current gps imei: 864507039648240, Current path: go\n",
      "Current gps imei: 864507039676258, Current path: go\n",
      "Current gps imei: 866381052399372, Current path: go\n",
      "Current gps imei: 866381052399851, Current path: go\n",
      "Current gps imei: 869530043171160, Current path: go\n",
      "Current gps imei: 868998031822683, Current path: go\n",
      "Current gps imei: 866381052397178, Current path: go\n",
      "Current gps imei: 866381052370225, Current path: go\n",
      "Current gps imei: 866381052370738, Current path: go\n",
      "Current gps imei: 866381052394621, Current path: go\n",
      "Current gps imei: 866381052358725, Current path: go\n",
      "Current gps imei: 866381052394605, Current path: go\n",
      "Current gps imei: 866381052384499, Current path: go\n",
      "Current gps imei: 866381052396675, Current path: go\n",
      "Current gps imei: 866381052396311, Current path: go\n",
      "Current gps imei: 866381052399299, Current path: go\n",
      "Current gps imei: 869530043171871, Current path: go\n",
      "Current gps imei: 869530043171863, Current path: go\n",
      "Current gps imei: 868998030595546, Current path: go\n",
      "Current gps imei: 866381052396238, Current path: go\n",
      "Current gps imei: 868998030635219, Current path: go\n",
      "Current gps imei: 866381052397913, Current path: go\n",
      "Current gps imei: 866381052388714, Current path: go\n",
      "Current gps imei: 868998030633305, Current path: go\n",
      "Current gps imei: 866381052370209, Current path: go\n",
      "Current gps imei: 866381052370092, Current path: go\n",
      "Current gps imei: 866381052370167, Current path: go\n",
      "Current gps imei: 866381052388771, Current path: go\n",
      "Current gps imei: 866381052396634, Current path: go\n",
      "Current gps imei: 868998030594861, Current path: go\n",
      "Current gps imei: 866381052370019, Current path: back\n",
      "Current gps imei: 868998030587691, Current path: back\n",
      "Current gps imei: 866381052370324, Current path: back\n",
      "Current gps imei: 867553050796408, Current path: back\n",
      "Current gps imei: 867553050806694, Current path: back\n",
      "Current gps imei: 868998030645952, Current path: back\n",
      "Current gps imei: 866381052370274, Current path: back\n",
      "Current gps imei: 868998030639021, Current path: back\n",
      "Current gps imei: 868998030633206, Current path: back\n",
      "Current gps imei: 864507039711451, Current path: back\n",
      "Current gps imei: 866381052397160, Current path: back\n",
      "Current gps imei: 864507039641906, Current path: back\n",
      "Current gps imei: 868998030618942, Current path: back\n",
      "Current gps imei: 864507039711535, Current path: back\n",
      "Current gps imei: 869530043171988, Current path: back\n",
      "Current gps imei: 866381052390660, Current path: back\n",
      "Current gps imei: 866381052394969, Current path: back\n",
      "Current gps imei: 866381052393128, Current path: back\n",
      "Current gps imei: 866381052397095, Current path: back\n",
      "Current gps imei: 869530043171145, Current path: back\n",
      "Current gps imei: 864507039674154, Current path: back\n",
      "Current gps imei: 868998030627521, Current path: back\n",
      "Current gps imei: 868998030635771, Current path: back\n",
      "Current gps imei: 866381052399695, Current path: back\n",
      "Current gps imei: 866381052396907, Current path: back\n",
      "Current gps imei: 868998030587931, Current path: back\n",
      "Current gps imei: 866381052399125, Current path: back\n",
      "Current gps imei: 868998030588186, Current path: back\n",
      "Current gps imei: 863835027811913, Current path: back\n",
      "Current gps imei: 864507039665376, Current path: back\n",
      "Current gps imei: 866381052396683, Current path: back\n",
      "Current gps imei: 868998030634774, Current path: back\n",
      "Current gps imei: 864507039672166, Current path: back\n",
      "Current gps imei: 864507039673982, Current path: back\n",
      "Current gps imei: 868998030634154, Current path: back\n",
      "Current gps imei: 869530043171822, Current path: back\n",
      "Current gps imei: 863835026096490, Current path: back\n",
      "Current gps imei: 868998030615351, Current path: back\n",
      "Current gps imei: 869530043173083, Current path: back\n",
      "Current gps imei: 864507039720817, Current path: back\n",
      "Current gps imei: 864507039648240, Current path: back\n",
      "Current gps imei: 864507039676258, Current path: back\n",
      "Current gps imei: 866381052399372, Current path: back\n",
      "Current gps imei: 866381052399851, Current path: back\n",
      "Current gps imei: 869530043171160, Current path: back\n",
      "Current gps imei: 868998031822683, Current path: back\n",
      "Current gps imei: 866381052397178, Current path: back\n",
      "Current gps imei: 866381052370225, Current path: back\n",
      "Current gps imei: 866381052370738, Current path: back\n",
      "Current gps imei: 866381052394621, Current path: back\n",
      "Current gps imei: 866381052358725, Current path: back\n",
      "Current gps imei: 866381052394605, Current path: back\n",
      "Current gps imei: 866381052384499, Current path: back\n",
      "Current gps imei: 866381052396675, Current path: back\n",
      "Current gps imei: 866381052396311, Current path: back\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current gps imei: 866381052399299, Current path: back\n",
      "Current gps imei: 869530043171871, Current path: back\n",
      "Current gps imei: 869530043171863, Current path: back\n",
      "Current gps imei: 868998030595546, Current path: back\n",
      "Current gps imei: 866381052396238, Current path: back\n",
      "Current gps imei: 868998030635219, Current path: back\n",
      "Current gps imei: 866381052397913, Current path: back\n",
      "Current gps imei: 866381052388714, Current path: back\n",
      "Current gps imei: 868998030633305, Current path: back\n",
      "Current gps imei: 866381052370209, Current path: back\n",
      "Current gps imei: 866381052370092, Current path: back\n",
      "Current gps imei: 866381052370167, Current path: back\n",
      "Current gps imei: 866381052388771, Current path: back\n",
      "Current gps imei: 866381052396634, Current path: back\n",
      "Current gps imei: 868998030594861, Current path: back\n",
      "Current gps imei: 868998030587691, Current path: go\n",
      "Current gps imei: 867553050796408, Current path: go\n",
      "Current gps imei: 867553050806694, Current path: go\n",
      "Current gps imei: 868998030633206, Current path: go\n",
      "Current gps imei: 868998030618942, Current path: go\n",
      "Current gps imei: 864507039711535, Current path: go\n",
      "Current gps imei: 869530043171988, Current path: go\n",
      "Current gps imei: 866381052390660, Current path: go\n",
      "Current gps imei: 866381052393128, Current path: go\n",
      "Current gps imei: 868998030635771, Current path: go\n",
      "Current gps imei: 868998030633305, Current path: go\n",
      "Current gps imei: 868998030594861, Current path: go\n",
      "Current gps imei: 868998030587691, Current path: back\n",
      "Current gps imei: 867553050796408, Current path: back\n",
      "Current gps imei: 867553050806694, Current path: back\n",
      "Current gps imei: 868998030633206, Current path: back\n",
      "Current gps imei: 868998030618942, Current path: back\n",
      "Current gps imei: 864507039711535, Current path: back\n",
      "Current gps imei: 869530043171988, Current path: back\n",
      "Current gps imei: 866381052390660, Current path: back\n",
      "Current gps imei: 866381052393128, Current path: back\n",
      "Current gps imei: 868998030635771, Current path: back\n",
      "Current gps imei: 868998030633305, Current path: back\n",
      "Current gps imei: 868998030594861, Current path: back\n",
      "Current gps imei: 868998030639021, Current path: go\n",
      "Current gps imei: 864507039711451, Current path: go\n",
      "Current gps imei: 864507039711535, Current path: go\n",
      "Current gps imei: 864507039674154, Current path: go\n",
      "Current gps imei: 868998030627521, Current path: go\n",
      "Current gps imei: 868998030635771, Current path: go\n",
      "Current gps imei: 868998030587931, Current path: go\n",
      "Current gps imei: 863835027811913, Current path: go\n",
      "Current gps imei: 864507039665376, Current path: go\n",
      "Current gps imei: 868998030634774, Current path: go\n",
      "Current gps imei: 864507039673982, Current path: go\n",
      "Current gps imei: 869530043171822, Current path: go\n",
      "Current gps imei: 863835026096490, Current path: go\n",
      "Current gps imei: 868998030615351, Current path: go\n",
      "Current gps imei: 869530043173083, Current path: go\n",
      "Current gps imei: 864507039648240, Current path: go\n",
      "Current gps imei: 868998031822683, Current path: go\n",
      "Current gps imei: 866381052358725, Current path: go\n",
      "Current gps imei: 866381052399299, Current path: go\n",
      "Current gps imei: 868998030635219, Current path: go\n",
      "Current gps imei: 868998030639021, Current path: back\n",
      "Current gps imei: 864507039711451, Current path: back\n",
      "Current gps imei: 864507039711535, Current path: back\n",
      "Current gps imei: 864507039674154, Current path: back\n",
      "Current gps imei: 868998030627521, Current path: back\n",
      "Current gps imei: 868998030635771, Current path: back\n",
      "Current gps imei: 868998030587931, Current path: back\n",
      "Current gps imei: 863835027811913, Current path: back\n",
      "Current gps imei: 864507039665376, Current path: back\n",
      "Current gps imei: 868998030634774, Current path: back\n",
      "Current gps imei: 864507039673982, Current path: back\n",
      "Current gps imei: 869530043171822, Current path: back\n",
      "Current gps imei: 863835026096490, Current path: back\n",
      "Current gps imei: 868998030615351, Current path: back\n",
      "Current gps imei: 869530043173083, Current path: back\n",
      "Current gps imei: 864507039648240, Current path: back\n",
      "Current gps imei: 868998031822683, Current path: back\n",
      "Current gps imei: 866381052358725, Current path: back\n",
      "Current gps imei: 866381052399299, Current path: back\n",
      "Current gps imei: 868998030635219, Current path: back\n"
     ]
    }
   ],
   "source": [
    "file = '/home/jovyan/work/data/all_arrival_time/arrival_time.csv'\n",
    "d = pd.read_csv(file)\n",
    "routes = d.route_num.unique().tolist()\n",
    "path_list = ['go','back']\n",
    "\n",
    "for route_num in routes:\n",
    "    # combine to links\n",
    "    link=[]\n",
    "    gps = d[d.route_num==route_num]\n",
    "    # gps = gps[gps.path == 'go']\n",
    "\n",
    "    for path in path_list:\n",
    "        for gps_imei in gps.gps_imei.unique().tolist():\n",
    "            df = gps[gps.gps_imei == gps_imei]\n",
    "            df = df[df.path == path]\n",
    "            print(f\"Current gps imei: {gps_imei}, Current path: {path}\")\n",
    "\n",
    "            for loop in df.loop_num.unique().tolist():\n",
    "                if len(link)==0:\n",
    "                    link_name = []\n",
    "                    link_time = []\n",
    "                    link_timestamp = []\n",
    "                    temp = df[df.loop_num == loop]\n",
    "                    for i in range(len(temp)-1):\n",
    "                        if temp.station_num.tolist()[i+1] - temp.station_num.tolist()[i] == 1:\n",
    "                            link_name.append(f'{temp.station_num.tolist()[i]}_{temp.station_num.tolist()[i+1]}')\n",
    "                            link_time.append((pd.to_datetime(temp.time.iloc[i+1]) - pd.to_datetime(temp.time.iloc[i])).seconds)\n",
    "                            link_timestamp.append(temp.time.tolist()[i+1])\n",
    "                    link = pd.DataFrame(link_name)\n",
    "                    # link.rename(columns={'0':'link_name'})\n",
    "                    link['link_time(sec)'] = link_time\n",
    "                    link['link_timestamp'] = link_timestamp\n",
    "                    link['path'] = [path]*len(link)\n",
    "                else:\n",
    "                    link_name = []\n",
    "                    link_time = []\n",
    "                    link_timestamp = []\n",
    "                    temp = df[df.loop_num == loop]\n",
    "                    for i in range(len(temp)-1):\n",
    "                        if temp.station_num.tolist()[i+1] - temp.station_num.tolist()[i] == 1:\n",
    "                            link_name.append(f'{temp.station_num.tolist()[i]}_{temp.station_num.tolist()[i+1]}')\n",
    "                            link_time.append((pd.to_datetime(temp.time.iloc[i+1]) - pd.to_datetime(temp.time.iloc[i])).seconds)\n",
    "                            link_timestamp.append(temp.time.tolist()[i+1])\n",
    "                    tmp = pd.DataFrame(link_name)\n",
    "                    # tmp.rename(columns={'0':'link_name'})\n",
    "                    tmp['link_time(sec)'] = link_time\n",
    "                    tmp['link_timestamp'] = link_timestamp\n",
    "                    tmp['path'] = [path]*len(tmp)\n",
    "                    link = pd.concat([link,tmp],axis=0)\n",
    "    link = link.sort_values('link_timestamp')\n",
    "    link.columns = ['link_name', 'link_time', 'link_timestamp', 'path']\n",
    "    link.to_csv(f'/home/jovyan/work/data/links/link_{route_num}_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f2c35950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link_name</th>\n",
       "      <th>link_time</th>\n",
       "      <th>link_timestamp</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_1</td>\n",
       "      <td>90</td>\n",
       "      <td>2022-03-22 06:04:44</td>\n",
       "      <td>go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_2</td>\n",
       "      <td>60</td>\n",
       "      <td>2022-03-22 06:05:44</td>\n",
       "      <td>go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2_3</td>\n",
       "      <td>120</td>\n",
       "      <td>2022-03-22 06:07:44</td>\n",
       "      <td>go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3_4</td>\n",
       "      <td>90</td>\n",
       "      <td>2022-03-22 06:09:14</td>\n",
       "      <td>go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4_5</td>\n",
       "      <td>30</td>\n",
       "      <td>2022-03-22 06:09:44</td>\n",
       "      <td>go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>74_75</td>\n",
       "      <td>15</td>\n",
       "      <td>2022-04-18 23:45:33</td>\n",
       "      <td>go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>75_76</td>\n",
       "      <td>30</td>\n",
       "      <td>2022-04-18 23:46:03</td>\n",
       "      <td>go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>76_77</td>\n",
       "      <td>30</td>\n",
       "      <td>2022-04-18 23:46:33</td>\n",
       "      <td>go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>77_78</td>\n",
       "      <td>45</td>\n",
       "      <td>2022-04-18 23:47:18</td>\n",
       "      <td>go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>78_79</td>\n",
       "      <td>360</td>\n",
       "      <td>2022-04-18 23:53:18</td>\n",
       "      <td>go</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>171911 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   link_name  link_time       link_timestamp path\n",
       "0        0_1         90  2022-03-22 06:04:44   go\n",
       "1        1_2         60  2022-03-22 06:05:44   go\n",
       "2        2_3        120  2022-03-22 06:07:44   go\n",
       "3        3_4         90  2022-03-22 06:09:14   go\n",
       "4        4_5         30  2022-03-22 06:09:44   go\n",
       "..       ...        ...                  ...  ...\n",
       "72     74_75         15  2022-04-18 23:45:33   go\n",
       "73     75_76         30  2022-04-18 23:46:03   go\n",
       "74     76_77         30  2022-04-18 23:46:33   go\n",
       "75     77_78         45  2022-04-18 23:47:18   go\n",
       "76     78_79        360  2022-04-18 23:53:18   go\n",
       "\n",
       "[171911 rows x 4 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e31e00fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/jovyan/work/data/links/link_133_test.csv',\n",
       " '/home/jovyan/work/data/links/link_6.csv',\n",
       " '/home/jovyan/work/data/links/link_56_test.csv',\n",
       " '/home/jovyan/work/data/links/link_133.csv',\n",
       " '/home/jovyan/work/data/links/link_56.csv',\n",
       " '/home/jovyan/work/data/links/link_35_test.csv',\n",
       " '/home/jovyan/work/data/links/link_35.csv',\n",
       " '/home/jovyan/work/data/links/link_6_test.csv']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "glob('/home/jovyan/work/data/links/*')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
